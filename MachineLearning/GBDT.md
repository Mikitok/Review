## Questions

**Q：为什么GBDT要用用损失函数的负梯度来拟合？**

GDBT是一个加法模型，在不改变上一轮模型的情况下，找到一个新的基学习器使得损失最小。使用负梯度可以将这个模型推广到不同的损失函数上。如果损失函数是平方损失的话可以直接用残差来拟合。

**Q：GBDT可以并行吗？**

GBDT的整体是串行运行的，但在每一轮迭代时，仍然有一些部分可以并行算。
1. 计算每个样本的负梯度。
2. 在拟合残差树时某个节点分类时，求各种可能的分类情况时的增益是可以并行计算的。但是计算整棵树的时候还是要串行计算的，下一个节点的最大增益要在它的父节点生成后才可以求。
3. 在预测过程中，每个样本将在所有树的计算是可以并行的。

**Q：GBDT的训练过程**

GBDT通过多轮迭代,每轮迭代产生一个弱分类器，每个分类器在上一轮分类器的残差基础上进行训练。弱分类器一般会选择为CART。然后将多个弱分类器的结果相加作为最终结果。

**Q：GBDT如何选择特征？**

由于GBDT的弱分类器一般会选择为CART回归树，所以特征选择方法和CART相同。

**Q：GBDT+LR和只用GBDT的区别**

GDBT是将一系列弱分类器的结果求和作为最终的结果。而在GBDT+LR中，GBDT是用来做特征组合和特征选择的，利用 GBDT 模型学习到的树来构造征，这些特征最后把这些新特征加入原有特征一起训练模型。构造的新特征向量是取值 0/1 的，向量的每个元素对应于 GBDT 模型中树的叶子结点。最终的分类是由LR完成。

**Q：gbdt可以用线性的基学习器吗？**

## References
1. [GBDT哪些部分可以并行](https://blog.csdn.net/weixin_40363423/article/details/98878459)
2. [GBDT和LR结合使用分析](https://blog.csdn.net/hellozhxy/article/details/81173871)
